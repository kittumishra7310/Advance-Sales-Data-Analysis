# Advanced Sales Data Analysis Project

## Overview

This project presents an advanced end-to-end data science workflow for analyzing, interpreting, and predicting sales performance using a comprehensive sample sales dataset. The project demonstrates powerful techniques including data cleaning, exploratory analysis, feature engineering, advanced visualizations, anomaly detection, time series forecasting, customer segmentation, and predictive modeling.

## Dataset

- **Source:** `sales_data_sample.csv`
- **Columns include:** Order details, quantities, product info, prices, customer/geography data, and sales status.

## Key Features

- **Robust Data Cleaning:** Missing value handling, deduplication, and data type correction
- **Descriptive Analytics:** Summary statistics, groupings, and pivot analysis for business insights
- **Feature Engineering:** Creation of new variables (e.g., estimated profit, temporal features)
- **Comprehensive EDA:** Boxplots, heatmaps, pairplots, and time series trend analysis
- **Segmentation:** Customer and product clustering with KMeans
- **Anomaly Detection:** Discovery of abnormal/suspicious transactions (Isolation Forest)
- **Predictive Modeling:** Linear regression and XGBoost for predicting sales
- **Time Series Forecasting:** Prophet for monthly sales forecasts
- **Automated Reporting:** Exported segmented data for stakeholder review

## Technologies and Tools

- **Languages:** Python 3
- **Libraries:** pandas, numpy, matplotlib, seaborn, scikit-learn, XGBoost, Prophet, Plotly
- **Techniques:** Regression, clustering, outlier detection, time series analysis

## Unique Aspects

- Hybrid of traditional BI reports and state-of-the-art machine learning/AI
- Modular, repeatable pipeline for any sales dataset
- Interactive and publication-quality visualizations
- Both unsupervised (segmentation, anomaly detection) and supervised (prediction, forecasting) ML
- Export functions for integrating with downstream business processes

## How to Run

1. Clone or upload the notebook and dataset.
2. Install required libraries as needed (`pip install -r requirements.txt`).
3. Run each notebook cell sequentially (all code is ready-to-run).
4. Visualizations and results will be produced inline.


